{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classificação_Rede_Neural.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2j41nu2xPVE"
      },
      "source": [
        "#Banco de Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "sPl4woVuxFLH",
        "outputId": "e81cb702-71dc-4f6f-c652-a24330289995"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "colunas = open('colunas_vinho.txt', 'r')\r\n",
        "nome_colunas = [coluna[:-1] for coluna in colunas]\r\n",
        "colunas.close()\r\n",
        "bd_vinho = pd.read_csv('banco_vinho.csv',names=nome_colunas, header=None)\r\n",
        "bd_vinho.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Vinho</th>\n",
              "      <th>Alcohol</th>\n",
              "      <th>Malic acid</th>\n",
              "      <th>Ash</th>\n",
              "      <th>Alcalinity of ash</th>\n",
              "      <th>Magnesium</th>\n",
              "      <th>Total phenols</th>\n",
              "      <th>Flavanoids</th>\n",
              "      <th>Nonflavanoid phenols</th>\n",
              "      <th>Proanthocyanins</th>\n",
              "      <th>Color intensity</th>\n",
              "      <th>Hue</th>\n",
              "      <th>Diluted wines</th>\n",
              "      <th>Prolin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Vinho  Alcohol  Malic acid  ...   Hue  Diluted wines  Prolin\n",
              "0      1    14.23        1.71  ...  1.04           3.92    1065\n",
              "1      1    13.20        1.78  ...  1.05           3.40    1050\n",
              "2      1    13.16        2.36  ...  1.03           3.17    1185\n",
              "3      1    14.37        1.95  ...  0.86           3.45    1480\n",
              "4      1    13.24        2.59  ...  1.04           2.93     735\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg1GvdDj6PeU"
      },
      "source": [
        "#Executar Rede Neural"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OIj2tSR9YZE"
      },
      "source": [
        "from arquiteturas_rede_neural.arquiteturas import *\r\n",
        "from bancos_de_dados.bd_tratado import *\r\n",
        "import time\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "arquitetura = criar_arquitetura_vinho()\r\n",
        "num_epocas = 500\r\n",
        "learning_rate = 1\r\n",
        "num_execucoes = 10\r\n",
        "\r\n",
        "rede = arquitetura\r\n",
        "rede.learning_rate = learning_rate\r\n",
        "rede.insere_sinapses_e_bias()\r\n",
        "coluna_alvo = rede.banco.columns[rede.atributos_de_saida[0]]  # continente, Vinho, vidro, iris\r\n",
        "banco = rede.banco\r\n",
        "tempos = np.array([])\r\n",
        "\r\n",
        "#Cria os vetores que armazenarão as acuracias referentes a cada sub-banco\r\n",
        "acuracia_treino = np.zeros(num_execucoes)\r\n",
        "acuracia_teste = np.zeros(num_execucoes)\r\n",
        "acuracia_total = np.zeros(num_execucoes)\r\n",
        "for execucao in range(num_execucoes):\r\n",
        "    print('\\nexecução : ', execucao)\r\n",
        "    tempo_inicial = time.perf_counter()\r\n",
        "    #cria uma nova rede\r\n",
        "    rede = arquitetura\r\n",
        "    rede.learning_rate = learning_rate\r\n",
        "    rede.insere_sinapses_e_bias()\r\n",
        "\r\n",
        "    #define as bases de treino e teste\r\n",
        "    base_treino, base_teste, tipos_saidas = tratar_bd(banco, coluna_alvo)\r\n",
        "    base_treino = base_treino.sample(frac=1).reset_index(drop=True)\r\n",
        "\r\n",
        "    #Realiza o backpropagation na função aprender\r\n",
        "    rede.aprender(num_epocas, base_treino)\r\n",
        "\r\n",
        "    #Realiza o teste de cada base e retorna as matrizes de confusão\r\n",
        "    matriz_treino = rede.testar(tipos_saidas, base_treino)\r\n",
        "    matriz_teste = rede.testar(tipos_saidas, base_teste)\r\n",
        "    matriz_total = rede.testar(tipos_saidas, banco)\r\n",
        "\r\n",
        "    tempos = np.append(tempos, time.perf_counter() - tempo_inicial)\r\n",
        "\r\n",
        "    #Utiliza a função calcula resultados para usar as matrizes de confusão e \r\n",
        "    #coletar os dados referentes a sensibilidade, confiabilidades etc...\r\n",
        "    print('base de treino: ')\r\n",
        "    acuracia_treino[execucao] = calcula_resultados(matriz_treino, True)\r\n",
        "    print('base de teste: ')\r\n",
        "    acuracia_teste[execucao] = calcula_resultados(matriz_teste, True)\r\n",
        "    print('base inteira: ')\r\n",
        "    acuracia_total[execucao] = calcula_resultados(matriz_total, True)\r\n",
        "print('')\r\n",
        "print('media de treino: ', np.mean(acuracia_treino))\r\n",
        "print('media de teste: ', np.mean(acuracia_teste))\r\n",
        "print('media de total: ', np.mean(acuracia_total))\r\n",
        "print('')\r\n",
        "print('desvio padrão de treino: ', np.std(acuracia_treino))\r\n",
        "print('desvio padrão de teste: ', np.std(acuracia_teste))\r\n",
        "print('desvio padrão de total: ', np.std(acuracia_total))\r\n",
        "print()\r\n",
        "print('Tempo médio de execução: ', np.mean(tempos))\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glAtmYWasHba"
      },
      "source": [
        "# Objeto Camada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MulsqDzbr0R5"
      },
      "source": [
        "import numpy as np\r\n",
        "#Objeto camada, representando todas as possíveis camadas da arquitetura,\r\n",
        "#seja ela de entrada, oculta ou final. Possui atributos  para armazenar\r\n",
        "#valores importantes como número de neurônios, os valores presentes nos\r\n",
        "#neurônios, as sinapses que a conectam com a próxima camada, o bias e o\r\n",
        "#erro que são utilizados no Feedfoward e no Backpropagation.\r\n",
        "class Camada:\r\n",
        "    def __init__(self, numero_neuronios, final=False):\r\n",
        "        self.numero_neuronios = numero_neuronios\r\n",
        "        self.neuronios = np.zeros((numero_neuronios, 1))\r\n",
        "        self.sinapses = None\r\n",
        "        self.final = final\r\n",
        "        self.bias = np.zeros((numero_neuronios, 1))\r\n",
        "        self.erro = None\r\n",
        "\r\n",
        "#Este método serve para que possamos modificar o número de neurônios da\r\n",
        "#camada, como alguns atributos dependem dessa variável, criamos este\r\n",
        "#método para atualizar tanto o número de neurônios, quanto outros atributos\r\n",
        "#que dependem dele.\r\n",
        "    def atualiza_numero_de_neuronios(self, numero_neuronios):\r\n",
        "        self.numero_neuronios = numero_neuronios\r\n",
        "        self.neuronios = np.zeros((numero_neuronios, 1))\r\n",
        "        self.bias = np.zeros((numero_neuronios, 1))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cx2D5gTdsr1c"
      },
      "source": [
        "#Objeto Rede Neural"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRtg3v3SsRnV"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from camada import Camada\r\n",
        "from funcoes_uteis import sigmoide\r\n",
        "from funcoes_uteis import multiplicar_matrizes\r\n",
        "from funcoes_uteis import derivar_sigmoide\r\n",
        "from funcoes_uteis import tahn\r\n",
        "from ferramentas import *\r\n",
        "\r\n",
        "#O Objeto Rede Neural, onde ficarão armazenadas as camadas, especificações do\r\n",
        "#banco de dados como número de atributos de entrada e saída, o próprio banco\r\n",
        "#para utilização pode parte dela, e outros parâmetros de execução e informações\r\n",
        "#importantes como a linha atual que a rede está lendo do banco, o valor esperado\r\n",
        "#para a classe dessa linha entre outros.\r\n",
        "class Rede_Neural:\r\n",
        "    def __init__(self, atributos_entradas, atributos_saidas,  num_camadas, neuronios_por_camada_oculta, banco):\r\n",
        "        self.atributos_de_entrada = atributos_entradas\r\n",
        "        self.atributos_de_saida = atributos_saidas\r\n",
        "        self.banco = banco\r\n",
        "        self.num_entradas = self.atributos_de_entrada.size\r\n",
        "        self.num_saidas = self.atributos_de_saida.size\r\n",
        "        self.numero_camadas = num_camadas\r\n",
        "        self.neuronios_por_camada_oculta = neuronios_por_camada_oculta\r\n",
        "        self.camadas = self.cria_camadas()\r\n",
        "        self.valor_esperado = None\r\n",
        "        self.learning_rate = 1\r\n",
        "        self.linha_atual = None\r\n",
        "\r\n",
        "#Este método em essência serve para verificar se as camadas foram criadas de\r\n",
        "#forma correta, ele mostra na tela várias informações referentes a todas as\r\n",
        "#camadas da rede neural.\r\n",
        "    def mostra_informacoes_das_camadas(self):\r\n",
        "        print('')\r\n",
        "        for camada in range(self.numero_camadas):\r\n",
        "            print(\"Informações da camada %d: \" % camada)\r\n",
        "            print(\"Numero de neuronios: \", self.camadas[camada].numero_neuronios)\r\n",
        "            print(\"Camada final?: \", self.camadas[camada].final)\r\n",
        "            print(\"Sinapses da camada: \")\r\n",
        "            print(self.camadas[camada].sinapses, \"\\n\")\r\n",
        "\r\n",
        "#Este método é chamado no momento de criação da rede neural, ao mesmo tempo\r\n",
        "#ele irá criar as camadas conforme a arquitetura definida no arquivo de\r\n",
        "#execução do algoritmo.\r\n",
        "    def cria_camadas(self):\r\n",
        "        camadas = []\r\n",
        "        for camada in range(self.numero_camadas):\r\n",
        "            if camada == 0:\r\n",
        "                camadas.append(Camada(self.num_entradas))\r\n",
        "            elif camada == self.numero_camadas-1:\r\n",
        "                camadas.append(Camada(self.num_saidas))\r\n",
        "            else:\r\n",
        "                camadas.append(Camada(self.neuronios_por_camada_oculta))\r\n",
        "        camadas[-1].final = True\r\n",
        "        return camadas\r\n",
        "\r\n",
        "#Este método deve ser chamado imediatamente após a criação da rede, ele irá\r\n",
        "#inserir todas as sinapses entre todos os neurônios de todas as camadas, além\r\n",
        "#disso, ele irá inserir o vetor de bias que será utilizado no Feedfoward e\r\n",
        "#Backpropagation, as sinapses (pesos) são criados de forma aleatória, com \r\n",
        "#valores entre 0 e 1 para cada peso.\r\n",
        "    def insere_sinapses_e_bias(self):\r\n",
        "        for camada in range(self.numero_camadas):\r\n",
        "            if not self.camadas[camada].final:\r\n",
        "                camada_1 = self.camadas[camada]\r\n",
        "                camada_2 = self.camadas[camada+1]\r\n",
        "                linhas = camada_2.numero_neuronios\r\n",
        "                colunas = camada_1.numero_neuronios\r\n",
        "                sinapses = np.random.rand(linhas, colunas)\r\n",
        "                self.camadas[camada].sinapses = np.copy(sinapses)\r\n",
        "                self.camadas[camada].bias = np.zeros((self.camadas[camada + 1].numero_neuronios, 1))\r\n",
        "\r\n",
        "#Este método é responsável por inserir os atributos da linha que será lida na\r\n",
        "#primeira camada, por isso seu único parâmetro é a linha do banco que será lida.\r\n",
        "    def inserir_entradas(self, linha):\r\n",
        "        banco = self.banco.values\r\n",
        "        for entrada in range(self.num_entradas):\r\n",
        "            atributo = self.atributos_de_entrada[entrada]\r\n",
        "            self.camadas[0].neuronios[entrada] = sigmoide(banco[linha][atributo])\r\n",
        "\r\n",
        "#Este método definirá qual será o valor esperado, ou seja, o valor correto da\r\n",
        "#classe que possui os atributos na camada de entrada, note que este valor\r\n",
        "#já foi convertido para seu equivalente na função Sigmoide.\r\n",
        "    def inserir_saidas(self, linha):\r\n",
        "        banco = self.banco.values\r\n",
        "        for saida in range(self.num_saidas):\r\n",
        "            atributo = self.atributos_de_saida[saida]\r\n",
        "            valor = banco[linha][atributo]\r\n",
        "            #print(valor)\r\n",
        "            if valor == 'Iris-setosa':\r\n",
        "                valor = 1\r\n",
        "            elif valor == 'Iris-versicolor':\r\n",
        "                valor = 2\r\n",
        "            elif valor == 'Iris-virginica':\r\n",
        "                valor = 3\r\n",
        "            else:\r\n",
        "                valor = valor\r\n",
        "            self.valor_esperado = sigmoide(valor)\r\n",
        "\r\n",
        "#O método feedfoward fará os calculos necessários utilizando os valores na\r\n",
        "#camada de entrada para que se chegue ao valor de saída da rede, armazenado\r\n",
        "#na última camada.\r\n",
        "    def feedfoward(self):\r\n",
        "        #print(\"lendo linha: \", self.linha_atual)\r\n",
        "        for camada_atual in range(self.numero_camadas-1):\r\n",
        "            camada = self.camadas[camada_atual]\r\n",
        "            if not camada.final:\r\n",
        "                multiplicacao_matricial = multiplicar_matrizes(camada.sinapses, camada.neuronios)\r\n",
        "                multiplicacao_matricial = multiplicacao_matricial + camada.bias\r\n",
        "                self.camadas[camada_atual + 1].neuronios = sigmoide(multiplicacao_matricial)\r\n",
        "                '''print('sinapses ligadas a camada %d: ' % camada_atual)\r\n",
        "                print(camada.sinapses)\r\n",
        "                print('neuronios da camada atual: ')\r\n",
        "                print(camada.neuronios)\r\n",
        "                print('multiplicação das sinapses pelos neuronios: ')\r\n",
        "                print(self.camadas[camada_atual+1].neuronios)'''\r\n",
        "\r\n",
        "\r\n",
        "#O método a seguir serve para testar o feedfoward uma única ves em uma linha\r\n",
        "#do bando de dados, isso é importante para que possamos fazer verificações\r\n",
        "#únicas no bando depois que a rede já aprendeu, ou caso queiramos executar\r\n",
        "#o feedfoward várias vezes já inserindo as entradas e saídas podemos chamar\r\n",
        "#essa função em loop.\r\n",
        "    def testar_feed_foward(self, linha, banco):\r\n",
        "        self.banco = banco\r\n",
        "        self.inserir_entradas(linha)\r\n",
        "        self.inserir_saidas(linha)\r\n",
        "        self.linha_atual = linha\r\n",
        "        self.feedfoward()\r\n",
        "\r\n",
        "#Função para propagar o erro obtido na saída da rede neural, modificando os \r\n",
        "#pesos das sinapses entre as camadas, além de modificar o Bias\r\n",
        "    def backpropagation(self):\r\n",
        "        erro_saida = self.valor_esperado - self.camadas[-1].neuronios\r\n",
        "        derivada_saida = derivar_sigmoide(self.camadas[-1].neuronios)\r\n",
        "        transposta_oculto = np.transpose(self.camadas[-2].neuronios)\r\n",
        "\r\n",
        "        gradiente = np.multiply(derivada_saida, erro_saida)\r\n",
        "        gradiente = gradiente * self.learning_rate\r\n",
        "\r\n",
        "        self.camadas[-2].bias = self.camadas[-2].bias + gradiente\r\n",
        "\r\n",
        "        delta_pesos_oculto_saida = np.matmul(gradiente, transposta_oculto)\r\n",
        "        self.camadas[-2].sinapses = self.camadas[-2].sinapses + delta_pesos_oculto_saida\r\n",
        "        self.camadas[-1].erro = erro_saida\r\n",
        "\r\n",
        "        for i in range(self.numero_camadas - 2, 0, -1):\r\n",
        "            transposta_pesos = np.transpose(self.camadas[i].sinapses)\r\n",
        "            erro = np.matmul(transposta_pesos, self.camadas[i+1].erro)\r\n",
        "            derivada = derivar_sigmoide(self.camadas[i].neuronios)\r\n",
        "            transposta = np.transpose(self.camadas[i-1].neuronios)\r\n",
        "    \r\n",
        "            gradiente_O = np.multiply(erro, derivada)\r\n",
        "            gradiente_O = gradiente_O * self.learning_rate\r\n",
        "    \r\n",
        "            self.camadas[i-1].bias = self.camadas[i-1].bias + gradiente_O\r\n",
        "    \r\n",
        "            delta_pesos = np.matmul(gradiente_O, transposta)\r\n",
        "            self.camadas[i-1].sinapses = self.camadas[i-1].sinapses + delta_pesos\r\n",
        "            self.camadas[i].erro = erro\r\n",
        "\r\n",
        "#Função para testar o algoritmo após o aprendizado, apenas classificando as \r\n",
        "#amostras sem modificar os seus parâmetros\r\n",
        "    def aprender(self, num_epocas, base_treino):\r\n",
        "        self.banco = base_treino\r\n",
        "        num_linhas = len(base_treino)\r\n",
        "        for epocas in range(num_epocas):\r\n",
        "            for linha in range(num_linhas):\r\n",
        "                self.linha_atual = linha\r\n",
        "                self.inserir_entradas(linha)\r\n",
        "                self.inserir_saidas(linha)\r\n",
        "                self.feedfoward()\r\n",
        "                self.backpropagation()\r\n",
        "\r\n",
        "\r\n",
        "#Função que executa o aprendizado do algoritmo utilizando a base de treino. \r\n",
        "#A mesma utiliza outras funções, como o backpropagation() e o feedfoward()\r\n",
        "    def testar(self, tipos_saidas, base_teste):\r\n",
        "        matriz_confusao = np.zeros((len(tipos_saidas), len(tipos_saidas)))\r\n",
        "        num_linhas = len(base_teste)\r\n",
        "        resultado = None\r\n",
        "        base_numpy = base_teste.values\r\n",
        "\r\n",
        "        for linha in range(num_linhas):\r\n",
        "            self.testar_feed_foward(linha, base_teste)\r\n",
        "\r\n",
        "            valor_1 = sigmoide(tipos_saidas[0])\r\n",
        "            valor_2 = sigmoide(tipos_saidas[1])\r\n",
        "            valor_ultimo = sigmoide(tipos_saidas[-1])\r\n",
        "            valor_penultimo = sigmoide(tipos_saidas[-2])\r\n",
        "\r\n",
        "            if (len(tipos_saidas) == 2):\r\n",
        "                if self.camadas[-1].neuronios[0][0] < ((valor_1 + valor_2) / 2):\r\n",
        "                    resultado = np.where(tipos_saidas == tipos_saidas[0])\r\n",
        "                elif self.camadas[-1].neuronios[0][0] >= ((valor_1 + valor_2) / 2):\r\n",
        "                    resultado = np.where(tipos_saidas == tipos_saidas[-1])\r\n",
        "            else:\r\n",
        "                if self.camadas[-1].neuronios[0][0] < ((valor_1 + valor_2) / 2):\r\n",
        "                    resultado = np.where(tipos_saidas == tipos_saidas[0])\r\n",
        "\r\n",
        "                elif self.camadas[-1].neuronios[0][0] >= ((valor_1 + valor_2) / 2) and self.camadas[-1].neuronios[0][0] < ((valor_ultimo + valor_penultimo) / 2):\r\n",
        "                    for j in range(1, len(tipos_saidas) - 1):\r\n",
        "                        valor_1 = sigmoide(tipos_saidas[j])\r\n",
        "                        valor_2 = sigmoide(tipos_saidas[j - 1])\r\n",
        "                        valor_3 = sigmoide(tipos_saidas[j + 1])\r\n",
        "                        if (self.camadas[-1].neuronios[0][0] >= (valor_1 + valor_2)/2) and (self.camadas[-1].neuronios[0][0] < (valor_1 + valor_3))/2:\r\n",
        "                            resultado = np.where(tipos_saidas == tipos_saidas[j])\r\n",
        "\r\n",
        "                elif self.camadas[-1].neuronios[0][0] >= ((valor_ultimo + valor_penultimo) / 2):\r\n",
        "                    resultado = np.where(tipos_saidas == tipos_saidas[-1])\r\n",
        "\r\n",
        "            valor_teste = np.where(tipos_saidas == base_numpy[linha][self.atributos_de_saida[0]])\r\n",
        "            matriz_confusao[int(valor_teste[0])][int(resultado[0])] += 1\r\n",
        "        print(matriz_confusao)\r\n",
        "        return matriz_confusao"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_89vNbVusFZ5"
      },
      "source": [
        "# Funções do arquivo Funções Úteis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzbtWwlGtQ1e"
      },
      "source": [
        "#A função sigmoide é a principal função de ativação do algoritmo de rede neural,\r\n",
        "#ela será utilizada tanto na etapa de aprendizado quanto nas etapas de teste.\r\n",
        "def sigmoide(x):\r\n",
        "    return 1/(1+np.exp(-x))\r\n",
        "\r\n",
        "#A derivada da função de ativação é necessária na etapa de propagação do erro,\r\n",
        "#ou seja, na função Backpropagation.\r\n",
        "def derivar_sigmoide(x):\r\n",
        "    return x * (1 - x)\r\n",
        "\r\n",
        "#A função tahn é outra função de ativação presente na literatura, porém, não \r\n",
        "#utilizada neste trabalho efetivamente, apenas foi colocada aqui como exemplo.\r\n",
        "def tahn(x):\r\n",
        "    return 2 / (1 + np.exp(-2*x)) - 1\r\n",
        "\r\n",
        "#A função multiplica matrizes simplesmente recebe duas matrizes e as multiplica\r\n",
        "#utilizando um método da biblioteca Numpy.\r\n",
        "def multiplicar_matrizes(a, b):\r\n",
        "    return np.matmul(a, b)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZQUTkt8-bJQ"
      },
      "source": [
        "#Ferramentas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5C7EAri8-gC-"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "#calcula e retorna uma base de treino única\r\n",
        "def retorna_treino(base):\r\n",
        "    treino = base.sample(frac=0.7)\r\n",
        "    return treino\r\n",
        "\r\n",
        "#calcula e retorna uma base de teste única\r\n",
        "def retorna_teste(base, base_treino):\r\n",
        "    teste = base.drop(base_treino.index)\r\n",
        "    return teste\r\n",
        "\r\n",
        "#calcula sensibilidade, confiabilidades entre outros a partir da matriz de\r\n",
        "#confusão\r\n",
        "def calcula_resultados(matriz, verbose=False):\r\n",
        "    \r\n",
        "    num_classes = len(matriz)\r\n",
        "\r\n",
        "    sensibilidade = np.zeros([num_classes])\r\n",
        "    especificidade = np.zeros([num_classes])\r\n",
        "    confiabilidade_positiva = np.zeros([num_classes])\r\n",
        "    confiabilidade_negativa = np.zeros([num_classes])\r\n",
        "\r\n",
        "    tp = np.zeros([num_classes])\r\n",
        "    tn = np.zeros([num_classes])\r\n",
        "    fn = np.zeros([num_classes])\r\n",
        "    fp = np.zeros([num_classes])\r\n",
        "\r\n",
        "    acertos = 0\r\n",
        "    acuracia = 0\r\n",
        "    total = 0\r\n",
        "\r\n",
        "    for classe in range(num_classes):\r\n",
        "        for linha in range(num_classes):\r\n",
        "            for coluna in range(num_classes):\r\n",
        "                if classe == linha == coluna:\r\n",
        "                    tp[classe] += matriz[linha][coluna]\r\n",
        "                elif classe != linha == coluna:\r\n",
        "                    tn[classe] += matriz[linha][coluna]\r\n",
        "                elif classe == linha != coluna:\r\n",
        "                    fn[classe] += matriz[linha][coluna]\r\n",
        "                elif classe == coluna != linha:\r\n",
        "                    fp[classe] += matriz[linha][coluna]\r\n",
        "\r\n",
        "    if verbose:\r\n",
        "        print('TP =', tp)\r\n",
        "        print('TN =', tn)\r\n",
        "        print('FN =', fn)\r\n",
        "        print('FP =', fp)\r\n",
        "\r\n",
        "    for linha in range(num_classes):\r\n",
        "        for coluna in range(num_classes):\r\n",
        "            if linha == coluna:\r\n",
        "                acertos += matriz[linha][coluna]\r\n",
        "            total += matriz[linha][coluna]\r\n",
        "\r\n",
        "    acuracia = (acertos*100)/total\r\n",
        "\r\n",
        "    for classe in range(num_classes):\r\n",
        "        sensibilidade[classe] = tp[classe]/(tp[classe] + fn[classe])\r\n",
        "        especificidade[classe] = tn[classe]/(tn[classe] + fp[classe])\r\n",
        "        confiabilidade_positiva[classe] = tp[classe]/(tp[classe] + fp[classe])\r\n",
        "        confiabilidade_negativa[classe] = tn[classe]/(tn[classe] + fn[classe])\r\n",
        "        \r\n",
        "        if tp[classe] + fn[classe] == 0:\r\n",
        "            sensibilidade[classe] = 0\r\n",
        "        if tn[classe] + fp[classe] == 0:\r\n",
        "            especificidade[classe] = 0\r\n",
        "        if tp[classe] + fp[classe] == 0:\r\n",
        "            confiabilidade_positiva[classe] = 0\r\n",
        "        if tn[classe] + fn[classe] == 0:\r\n",
        "            confiabilidade_negativa[classe] = 0\r\n",
        "\r\n",
        "        if verbose:\r\n",
        "            print('----------- Classe %d -----------' %(classe+1))\r\n",
        "            print('Sensibilidade: ', sensibilidade[classe])\r\n",
        "            print('Especificidade: ', especificidade[classe])\r\n",
        "            print('Confiabilidade Positiva: ', confiabilidade_positiva[classe])\r\n",
        "            print('Confiabilidade Negativa: ', confiabilidade_negativa[classe])\r\n",
        "    if verbose:\r\n",
        "        print('Media da Sensibilidade: ', np.mean(sensibilidade))\r\n",
        "        print('Media da Especificidade: ', np.mean(especificidade))\r\n",
        "        print('Media da Confiabilidade Positiva: ', np.mean(confiabilidade_positiva))\r\n",
        "        print('Media da Confiabilidade Negativa: ', np.mean(confiabilidade_negativa))\r\n",
        "\r\n",
        "    if verbose:\r\n",
        "        print('Acurácia:', acuracia, end='\\n')\r\n",
        "\r\n",
        "    return acuracia"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}